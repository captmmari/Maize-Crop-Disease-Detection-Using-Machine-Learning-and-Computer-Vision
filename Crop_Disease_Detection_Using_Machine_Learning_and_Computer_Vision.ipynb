{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crop Disease Detection Using Machine Learning and Computer Vision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHU6XQH3O5tPApP3i3wev4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muthonioprah/Maize-Crop-Disease-Detection-Using-Machine-Learning-and-Computer-Vision/blob/main/Crop_Disease_Detection_Using_Machine_Learning_and_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "boxIV6HrpW6J"
      },
      "outputs": [],
      "source": [
        "#importing the necessary packages and libraries\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from collections import defaultdict\n",
        "from urllib import request\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib import request\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dropout,Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "import os\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import json\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIoetCfE1ac4",
        "outputId": "891bfe2a-c47e-4e6c-d260-e0df1b44d62f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assigning our values to variables\n",
        "batches = 50\n",
        "image_size = 256\n",
        "channels= 3\n",
        "epochs=80\n"
      ],
      "metadata": {
        "id": "Gd1TxoXEpyuy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dataset\n",
        "df = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Maize/Dataset\",\n",
        "    seed=123,\n",
        "    image_size=(image_size, image_size),\n",
        "    shuffle=True,\n",
        "    batch_size= batches\n",
        ")"
      ],
      "metadata": {
        "id": "3MTbyKy_phi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b5be4e-ef54-4676-cf68-b25428451f44"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 509 files belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#displaying class names\n",
        "categories = df.class_names\n",
        "categories"
      ],
      "metadata": {
        "id": "fg9rXSG_phes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ed738b-592b-40c1-fe54-e71c3c81d443"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Healthy Maize',\n",
              " 'Maize Common rust_',\n",
              " 'Maize Gray leaf spot',\n",
              " 'Maize Head smut',\n",
              " 'Maize northern leaf blight',\n",
              " 'Maize streak disease']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in df.take(10):\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.numpy())"
      ],
      "metadata": {
        "id": "pn14jT05ODvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "XkQEfakZrIZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize some of the images from our dataset\n",
        "plt.figure(figsize=(10, 10))\n",
        "for image_batch, labels_batch in df.take(20):\n",
        "    for i in range(1):\n",
        "        ax = plt.subplot(5, 4, i + 1)\n",
        "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(categories[labels_batch[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Smq4BKOQq2QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking dataset length\n",
        "print(len(df))\n",
        "train_size = 0.8\n",
        "print(len(df)*train_size)\n",
        "\n",
        "#train_df = df.take()\n",
        "#len(train_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "hjvLqYxZqIVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f31aa0d-24eb-4b14-9e93-edf22bcf409d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "8.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "test_df = defaultdict.skip(12)\n",
        "len(test_df)\n",
        "\n",
        "test_df = test_df.skip()\n",
        "len(test_df)"
      ],
      "metadata": {
        "id": "LwpmzLPJ0U4E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6ff025eb-771d-4b5c-9042-f89bc6bcd8d4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ac202658850a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'collections.defaultdict' has no attribute 'skip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_size= 0.1\n",
        "len(df)*val_size\n",
        "\n",
        "val_df = test_df.take(6)\n",
        "len(val_df)"
      ],
      "metadata": {
        "id": "aWIIXDC71nbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset to train and test\n",
        "def get_dataset_partitions_tf(df, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    ds_size = len(ds)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds\n"
      ],
      "metadata": {
        "id": "awinF_3DqIPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "Rn-x6adYqIEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "])"
      ],
      "metadata": {
        "id": "1NzRLfGaCWnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "lfkYX_taCWjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (data_augmentation(x, training=True), y)\n",
        ").prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7mmaAer5CWg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (batch_size, image_size, image_size, channels)\n",
        "n_classes = 3\n",
        "\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "W-19_YMiCWd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the Model\n",
        "#We use adam Optimizer, SparseCategoricalCrossentropy for losses, accuracy as a metric\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "Pua64UHtCWa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=val_df,\n",
        "    verbose=1,\n",
        "    epochs=50,\n",
        ")"
      ],
      "metadata": {
        "id": "3Jf1fxmyCWVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W_xCimCLCWO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yWvxuIvWC0eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OUQincd4C0YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UBhfr8uUC0Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EKvuVLkZC0PS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}